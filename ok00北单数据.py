import csv
import time
import random
import os
import json
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.action_chains import ActionChains
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from bs4 import BeautifulSoup
import pandas as pd
import undetected_chromedriver as uc


class EnhancedOkoooSpider:
    def __init__(self, headless=False):
        self.headless = headless
        self.driver = None
        self.existing_ids = set()
        self.csv_file = 'okooo_matches.csv'
        self.session_cookies = None
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
        self.setup_driver()
        self.load_existing_ids()

    def setup_driver(self):
        """è®¾ç½®æ›´å¼ºçš„åæ£€æµ‹Chromeé©±åŠ¨"""
        try:
            # ä½¿ç”¨undetected_chromedriverï¼Œå®ƒèƒ½æ›´å¥½åœ°ç»•è¿‡æ£€æµ‹
            chrome_options = uc.ChromeOptions()

            if self.headless:
                chrome_options.add_argument('--headless')

            # æ›´å…¨é¢çš„åæ£€æµ‹è®¾ç½®
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-plugins-discovery')
            chrome_options.add_argument('--disable-web-security')
            chrome_options.add_argument('--allow-running-insecure-content')
            chrome_options.add_argument('--no-first-run')
            chrome_options.add_argument('--disable-default-apps')
            chrome_options.add_argument('--disable-infobars')
            chrome_options.add_argument('--disable-notifications')
            chrome_options.add_argument('--disable-background-timer-throttling')
            chrome_options.add_argument('--disable-backgrounding-occluded-windows')
            chrome_options.add_argument('--disable-renderer-backgrounding')

            # éšæœºç”¨æˆ·ä»£ç†
            user_agent = random.choice(self.user_agents)
            chrome_options.add_argument(f'--user-agent={user_agent}')

            # çª—å£å¤§å°éšæœºåŒ–
            width = random.randint(1200, 1920)
            height = random.randint(800, 1080)
            chrome_options.add_argument(f'--window-size={width},{height}')

            # åˆ›å»ºé©±åŠ¨
            self.driver = uc.Chrome(options=chrome_options, version_main=None)

            # æ‰§è¡Œåæ£€æµ‹è„šæœ¬
            self.driver.execute_script("""
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
                Object.defineProperty(navigator, 'languages', {get: () => ['zh-CN', 'zh', 'en']});
                window.chrome = {runtime: {}};
                Object.defineProperty(navigator, 'permissions', {get: () => ({query: () => Promise.resolve({state: 'granted'})})});
            """)

            print("å¢å¼ºç‰ˆChromeé©±åŠ¨å·²å¯åŠ¨")

        except Exception as e:
            print(f"undetected_chromedriverå¯åŠ¨å¤±è´¥ï¼Œå°è¯•æ™®é€šChrome: {e}")
            # å¦‚æœundetected_chromedriverå¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šChrome
            self.setup_regular_chrome()

    def setup_regular_chrome(self):
        """è®¾ç½®æ™®é€šChromeé©±åŠ¨ä½œä¸ºå¤‡é€‰"""
        chrome_options = Options()

        if self.headless:
            chrome_options.add_argument('--headless')

        # åŸºæœ¬åæ£€æµ‹è®¾ç½®
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)

        # éšæœºç”¨æˆ·ä»£ç†
        user_agent = random.choice(self.user_agents)
        chrome_options.add_argument(f'--user-agent={user_agent}')

        # éšæœºçª—å£å¤§å°
        width = random.randint(1200, 1920)
        height = random.randint(800, 1080)
        chrome_options.add_argument(f'--window-size={width},{height}')

        self.driver = webdriver.Chrome(options=chrome_options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

    def load_existing_ids(self):
        """åŠ è½½å·²å­˜åœ¨çš„æ¯”èµ›ID"""
        if os.path.exists(self.csv_file):
            try:
                df = pd.read_csv(self.csv_file, encoding='utf-8-sig')
                if 'åºå·' in df.columns:
                    self.existing_ids = set(df['åºå·'].astype(str).tolist())
                    print(f"å·²åŠ è½½ {len(self.existing_ids)} ä¸ªç°æœ‰æ¯”èµ›ID")
            except Exception as e:
                print(f"åŠ è½½ç°æœ‰IDæ—¶å‡ºé”™: {e}")

    def save_session(self):
        """ä¿å­˜ä¼šè¯ä¿¡æ¯"""
        try:
            cookies = self.driver.get_cookies()
            session_data = {
                'cookies': cookies,
                'user_agent': self.driver.execute_script("return navigator.userAgent;"),
                'timestamp': time.time()
            }
            with open('session_data.json', 'w') as f:
                json.dump(session_data, f)
            print("ä¼šè¯ä¿¡æ¯å·²ä¿å­˜")
        except Exception as e:
            print(f"ä¿å­˜ä¼šè¯å¤±è´¥: {e}")

    def load_session(self):
        """åŠ è½½ä¼šè¯ä¿¡æ¯"""
        try:
            if os.path.exists('session_data.json'):
                with open('session_data.json', 'r') as f:
                    session_data = json.load(f)

                # æ£€æŸ¥ä¼šè¯æ˜¯å¦è¿‡æœŸï¼ˆ24å°æ—¶ï¼‰
                if time.time() - session_data.get('timestamp', 0) < 24 * 3600:
                    # å…ˆè®¿é—®ç½‘ç«™ä¸»é¡µ
                    self.driver.get("https://www.okooo.com")
                    time.sleep(2)

                    # åŠ è½½cookies
                    for cookie in session_data['cookies']:
                        try:
                            self.driver.add_cookie(cookie)
                        except:
                            pass

                    print("å·²åŠ è½½ä¿å­˜çš„ä¼šè¯ä¿¡æ¯")
                    return True
        except Exception as e:
            print(f"åŠ è½½ä¼šè¯å¤±è´¥: {e}")
        return False

    def human_like_mouse_movement(self, element):
        """æ¨¡æ‹Ÿäººç±»é¼ æ ‡ç§»åŠ¨"""
        try:
            action = ActionChains(self.driver)

            # å…ˆç§»åŠ¨åˆ°éšæœºä½ç½®
            action.move_by_offset(random.randint(-100, 100), random.randint(-100, 100))
            action.perform()
            time.sleep(random.uniform(0.5, 1.0))

            # ç§»åŠ¨åˆ°å…ƒç´ é™„è¿‘
            action = ActionChains(self.driver)
            action.move_to_element_with_offset(element,
                                               random.randint(-5, 5),
                                               random.randint(-5, 5))
            action.perform()
            time.sleep(random.uniform(0.3, 0.8))

            # æœ€ç»ˆç§»åŠ¨åˆ°å…ƒç´ 
            action = ActionChains(self.driver)
            action.move_to_element(element)
            action.perform()
            time.sleep(random.uniform(0.2, 0.5))

        except Exception as e:
            print(f"é¼ æ ‡ç§»åŠ¨æ¨¡æ‹Ÿå¤±è´¥: {e}")

    def simulate_human_behavior(self):
        """æ¨¡æ‹Ÿäººç±»æµè§ˆè¡Œä¸º"""
        try:
            # éšæœºæ»šåŠ¨é¡µé¢
            scroll_height = random.randint(100, 500)
            self.driver.execute_script(f"window.scrollBy(0, {scroll_height});")
            time.sleep(random.uniform(1, 2))

            # éšæœºç‚¹å‡»ç©ºç™½åŒºåŸŸï¼ˆæ¨¡æ‹Ÿç”¨æˆ·æŸ¥çœ‹é¡µé¢ï¼‰
            body = self.driver.find_element(By.TAG_NAME, "body")
            action = ActionChains(self.driver)
            action.move_to_element_with_offset(body,
                                               random.randint(100, 500),
                                               random.randint(100, 300))
            action.click()
            action.perform()
            time.sleep(random.uniform(0.5, 1.5))

        except Exception as e:
            print(f"æ¨¡æ‹Ÿäººç±»è¡Œä¸ºå¤±è´¥: {e}")

    def handle_slider_captcha(self):
        """å¤„ç†æ»‘å—éªŒè¯ç """
        try:
            print("æ£€æµ‹åˆ°æ»‘å—éªŒè¯ç ï¼Œå°è¯•å¤„ç†...")

            # å¸¸è§çš„æ»‘å—éªŒè¯ç é€‰æ‹©å™¨
            slider_selectors = [
                '.geetest_slider_button',
                '.slide-verify-slider-mask-item',
                '.slider-button',
                '.captcha-slider-btn',
                '#slider'
            ]

            slider_element = None
            for selector in slider_selectors:
                try:
                    slider_element = WebDriverWait(self.driver, 5).until(
                        EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                    )
                    break
                except:
                    continue

            if slider_element:
                # æ¨¡æ‹Ÿäººç±»æ»‘åŠ¨
                action = ActionChains(self.driver)

                # å…ˆæ¨¡æ‹Ÿé¼ æ ‡ç§»åŠ¨åˆ°æ»‘å—
                self.human_like_mouse_movement(slider_element)

                # æŒ‰ä¸‹é¼ æ ‡
                action.click_and_hold(slider_element)
                action.perform()
                time.sleep(random.uniform(0.2, 0.5))

                # åˆ†æ®µæ»‘åŠ¨ï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º
                total_distance = random.randint(250, 300)
                segments = random.randint(8, 15)

                for i in range(segments):
                    segment_distance = total_distance // segments
                    # æ·»åŠ éšæœºæ‰°åŠ¨
                    x_move = segment_distance + random.randint(-3, 3)
                    y_move = random.randint(-2, 2)

                    action.move_by_offset(x_move, y_move)
                    action.perform()

                    # éšæœºåœé¡¿
                    time.sleep(random.uniform(0.05, 0.15))

                # é‡Šæ”¾é¼ æ ‡
                action.release()
                action.perform()

                print("æ»‘å—æ“ä½œå®Œæˆï¼Œç­‰å¾…éªŒè¯ç»“æœ...")
                time.sleep(3)

                return True

        except Exception as e:
            print(f"å¤„ç†æ»‘å—éªŒè¯ç å¤±è´¥: {e}")

        return False

    def check_anti_crawler(self):
        """æ£€æŸ¥åçˆ¬éªŒè¯ - ä¿®å¤å…³é”®è¯è¯¯åˆ¤"""
        try:
            current_url = self.driver.current_url
            page_text = self.driver.page_source
            title = self.driver.title if self.driver.title else ""

            # ä¼˜å…ˆæ£€æŸ¥é¡µé¢æ ‡é¢˜ - è¿™æ˜¯æœ€å‡†ç¡®çš„åˆ¤æ–­æ–¹å¼
            if title:
                title_lower = title.lower()
                verification_titles = [
                    "æ»‘åŠ¨éªŒè¯",
                    "è®¿é—®éªŒè¯",
                    "å®‰å…¨éªŒè¯",
                    "éªŒè¯å¤±è´¥",
                    "blocked",
                    "403",
                    "404",
                    "405",
                    "error"
                ]

                for verify_title in verification_titles:
                    if verify_title in title_lower:
                        print(f"ğŸš¨ æ ‡é¢˜æ˜¾ç¤ºéªŒè¯é¡µé¢: {title}")
                        return True

            # æ£€æŸ¥URLé‡å®šå‘
            error_url_patterns = ["error", "blocked", "verify", "captcha", "security"]
            current_url_lower = current_url.lower()
            for pattern in error_url_patterns:
                if pattern in current_url_lower:
                    print(f"ğŸš¨ URLé‡å®šå‘åˆ°é”™è¯¯é¡µé¢: {current_url}")
                    return True

            # æ£€æŸ¥é¡µé¢ä¸­çš„æ˜ç¡®éªŒè¯æç¤ºï¼ˆéœ€è¦åŒæ—¶å‡ºç°å¤šä¸ªå…³é”®è¯æ‰åˆ¤å®šï¼‰
            strong_verification_phrases = [
                "å¾ˆæŠ±æ­‰ï¼Œç”±äºæ‚¨è¯¢é—®çš„URLæœ‰å¯èƒ½å¯¹ç½‘ç«™é€ æˆå®‰å…¨å¨èƒ",
                "è¯·å®Œæˆå®‰å…¨éªŒè¯",
                "æ»‘åŠ¨ä¸‹æ–¹æ»‘å—å®ŒæˆéªŒè¯",
                "æ‹–åŠ¨æ»‘å—å®ŒæˆéªŒè¯",
                "ç‚¹å‡»å®ŒæˆéªŒè¯",
                "ac11000117543290780328834e65d1"  # æ‚¨æåˆ°çš„å…·ä½“ID
            ]

            for phrase in strong_verification_phrases:
                if phrase in page_text:
                    print(f"ğŸš¨ æ£€æµ‹åˆ°æ˜ç¡®éªŒè¯æç¤º: {phrase[:20]}...")
                    return True

            # æ£€æŸ¥é¡µé¢æ˜¯å¦å¼‚å¸¸çŸ­ï¼ˆæ˜æ˜¾é”™è¯¯é¡µé¢ï¼‰
            if len(page_text.strip()) < 1000:
                print(f"ğŸš¨ é¡µé¢å†…å®¹è¿‡çŸ­: {len(page_text)} å­—ç¬¦")
                return True

            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ»‘å—éªŒè¯çš„DOMç»“æ„ï¼ˆè€Œä¸æ˜¯ä»…ä»…åŒ…å«geeteståº“ï¼‰
            captcha_dom_indicators = [
                'class="geetest_panel"',
                'class="geetest_slider"',
                'id="captcha"',
                'class="slide-verify"',
                'class="captcha-container"'
            ]

            captcha_dom_count = sum(1 for indicator in captcha_dom_indicators if indicator in page_text)
            if captcha_dom_count >= 2:  # éœ€è¦å¤šä¸ªæŒ‡æ ‡åŒæ—¶å­˜åœ¨
                print(f"ğŸš¨ æ£€æµ‹åˆ°éªŒè¯ç DOMç»“æ„ (åŒ¹é…: {captcha_dom_count})")
                return True

            # å¦‚æœä»¥ä¸Šéƒ½æ²¡é—®é¢˜ï¼Œè®¤ä¸ºé¡µé¢æ­£å¸¸
            print("âœ… é¡µé¢çŠ¶æ€æ£€æŸ¥é€šè¿‡ï¼Œæ— éªŒè¯ç ")
            return False

        except Exception as e:
            print(f"âŒ æ£€æŸ¥é¡µé¢çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return False

    def is_normal_page(self):
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ­£å¸¸çš„æ¾³å®¢ç½‘é¡µé¢"""
        try:
            page_source = self.driver.page_source
            current_url = self.driver.current_url

            # æ£€æŸ¥URLæ˜¯å¦æ­£å¸¸
            if "okooo.com" not in current_url:
                print(f"âš ï¸ URLå¼‚å¸¸: {current_url}")
                return False

            # æ£€æŸ¥é¡µé¢å¿…è¦å…ƒç´ 
            required_elements = [
                "æ¾³å®¢ç½‘",
                "www.okooo.com",
                "livecenter"
            ]

            found_elements = sum(1 for element in required_elements if element in page_source)

            if found_elements < 2:
                print(f"âš ï¸ ç¼ºå°‘å¿…è¦é¡µé¢å…ƒç´  (æ‰¾åˆ° {found_elements}/{len(required_elements)})")
                return False

            # æ£€æŸ¥é¡µé¢é•¿åº¦
            if len(page_source) < 1000:
                print(f"âš ï¸ é¡µé¢å†…å®¹è¿‡çŸ­: {len(page_source)} å­—ç¬¦")
                return False

            print(f"âœ… é¡µé¢çŠ¶æ€æ­£å¸¸ (é•¿åº¦: {len(page_source)} å­—ç¬¦)")
            return True

        except Exception as e:
            print(f"âŒ åˆ¤æ–­é¡µé¢çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return False

    def has_match_data(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰æ¯”èµ›æ•°æ® - æ”¹è¿›ç‰ˆ"""
        try:
            # æ–¹æ³•1: æ£€æŸ¥æ¯”èµ›è¡Œå…ƒç´ 
            match_elements = self.driver.find_elements(By.CLASS_NAME, "each_match")
            if match_elements:
                print(f"âœ… æ‰¾åˆ° {len(match_elements)} ä¸ªæ¯”èµ›å…ƒç´ ")
                return True

            # æ–¹æ³•2: æ£€æŸ¥æ¯”èµ›ç›¸å…³çš„å…³é”®å…ƒç´ 
            key_selectors = [
                "a.ctrl_homename",  # ä¸»é˜Ÿé“¾æ¥
                "a.ctrl_awayname",  # å®¢é˜Ÿé“¾æ¥
                "b.ctrl_homescore",  # ä¸»é˜Ÿæ¯”åˆ†
                "tr[id*='match_detail_']"  # æ¯”èµ›è¯¦æƒ…è¡Œ
            ]

            for selector in key_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    print(f"âœ… é€šè¿‡é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªæ¯”èµ›ç›¸å…³å…ƒç´ ")
                    return True

            # æ–¹æ³•3: æ£€æŸ¥é¡µé¢æºç ä¸­çš„æ¯”èµ›æŒ‡æ ‡
            page_source = self.driver.page_source
            match_indicators = [
                "match_detail_",
                "ctrl_homename",
                "ctrl_awayname",
                "each_match"
            ]

            for indicator in match_indicators:
                if indicator in page_source:
                    print(f"âœ… åœ¨é¡µé¢æºç ä¸­æ‰¾åˆ°æ¯”èµ›æŒ‡æ ‡: {indicator}")
                    return True

            print("â„¹ï¸ æœªæ‰¾åˆ°æ¯”èµ›æ•°æ®ï¼Œå¯èƒ½å½“å¤©æ— æ¯”èµ›")
            return False

        except Exception as e:
            print(f"âŒ æ£€æŸ¥æ¯”èµ›æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def handle_verification_enhanced(self):
        """å¢å¼ºç‰ˆéªŒè¯å¤„ç†"""
        print("\n" + "ğŸ”’" * 20 + " é‡åˆ°éªŒè¯é¡µé¢ " + "ğŸ”’" * 20)

        # é¦–å…ˆå°è¯•è‡ªåŠ¨å¤„ç†æ»‘å—
        if self.handle_slider_captcha():
            time.sleep(3)
            if self.has_match_data():
                print("âœ… è‡ªåŠ¨æ»‘å—éªŒè¯æˆåŠŸï¼")
                return 'continue'

        # å¦‚æœè‡ªåŠ¨å¤„ç†å¤±è´¥ï¼Œè¿›è¡Œäººå·¥å¤„ç†
        print("ğŸ¤– è‡ªåŠ¨å¤„ç†å¤±è´¥ï¼Œéœ€è¦äººå·¥å¹²é¢„")
        print(f"ğŸ“„ å½“å‰é¡µé¢: {self.driver.current_url}")
        print(f"ğŸ“‹ é¡µé¢æ ‡é¢˜: {self.driver.title}")

        print("\nğŸ› ï¸ å¤„ç†é€‰é¡¹:")
        print("1. å›è½¦ - æ‰‹åŠ¨å®ŒæˆéªŒè¯åç»§ç»­")
        print("2. s + å›è½¦ - è·³è¿‡å½“å‰é¡µé¢")
        print("3. r + å›è½¦ - åˆ·æ–°é¡µé¢é‡è¯•")
        print("4. c + å›è½¦ - æ¸…é™¤cookiesé‡æ–°å¼€å§‹")
        print("5. q + å›è½¦ - é€€å‡ºç¨‹åº")

        choice = input("\né€‰æ‹©æ“ä½œ: ").strip().lower()

        if choice == 's':
            return 'skip'
        elif choice == 'r':
            self.driver.refresh()
            time.sleep(3)
            return 'continue'
        elif choice == 'c':
            self.driver.delete_all_cookies()
            print("Cookieså·²æ¸…é™¤")
            return 'continue'
        elif choice == 'q':
            return 'quit'
        else:
            return 'continue'

    def debug_page_status(self):
        """è°ƒè¯•é¡µé¢çŠ¶æ€ - æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯"""
        try:
            print(f"\n{'=' * 50}")
            print("ğŸ” é¡µé¢çŠ¶æ€è°ƒè¯•ä¿¡æ¯:")
            print(f"ğŸ“„ URL: {self.driver.current_url}")
            print(f"ğŸ“‹ æ ‡é¢˜: {self.driver.title}")

            # æ£€æŸ¥æ¯”èµ›æ•°æ®
            match_elements = self.driver.find_elements(By.CLASS_NAME, "each_match")
            print(f"ğŸˆ æ¯”èµ›è¡Œæ•°é‡: {len(match_elements)}")

            # æ£€æŸ¥å…³é”®å…ƒç´ 
            key_elements = {
                "ä¸»é˜Ÿé“¾æ¥": "a.ctrl_homename",
                "å®¢é˜Ÿé“¾æ¥": "a.ctrl_awayname",
                "æ¯”åˆ†å…ƒç´ ": "b.ctrl_homescore"
            }

            for name, selector in key_elements.items():
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                print(f"ğŸ” {name}: {len(elements)} ä¸ª")

            # é¡µé¢å†…å®¹é•¿åº¦
            page_length = len(self.driver.page_source)
            print(f"ğŸ“ é¡µé¢é•¿åº¦: {page_length} å­—ç¬¦")

            # æ£€æŸ¥å¯èƒ½çš„éªŒè¯ç æŒ‡æ ‡
            page_text = self.driver.page_source
            verification_checks = {
                "æ ‡é¢˜åŒ…å«éªŒè¯": any(word in (self.driver.title or "").lower()
                                    for word in ["éªŒè¯", "blocked", "error"]),
                "URLå¼‚å¸¸": any(word in self.driver.current_url.lower()
                               for word in ["error", "blocked", "verify"]),
                "é¡µé¢è¿‡çŸ­": page_length < 1000,
                "åŒ…å«éªŒè¯æç¤º": "æ»‘åŠ¨ä¸‹æ–¹æ»‘å—" in page_text or "å®ŒæˆéªŒè¯" in page_text
            }

            print("ğŸš¨ éªŒè¯ç æ£€æŸ¥:")
            for check, result in verification_checks.items():
                status = "âŒ" if result else "âœ…"
                print(f"   {status} {check}: {result}")

            print(f"{'=' * 50}\n")

        except Exception as e:
            print(f"âŒ è°ƒè¯•ä¿¡æ¯è·å–å¤±è´¥: {e}")

    def get_page_enhanced(self, url, max_retries=3):
        """å¢å¼ºç‰ˆé¡µé¢è·å– - æ·»åŠ è°ƒè¯•ä¿¡æ¯"""
        for attempt in range(max_retries):
            try:
                print(f"ğŸŒ è®¿é—®: {url} (å°è¯• {attempt + 1}/{max_retries})")

                # é‡è¯•å‰çš„ç­‰å¾…
                if attempt > 0:
                    wait_time = random.uniform(5, 10)
                    print(f"â³ ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                    time.sleep(wait_time)

                # è®¿é—®é¡µé¢å‰çš„éšæœºå»¶è¿Ÿ
                time.sleep(random.uniform(2, 4))

                # è®¿é—®é¡µé¢
                self.driver.get(url)

                # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
                WebDriverWait(self.driver, 20).until(
                    lambda driver: driver.execute_script("return document.readyState") == "complete"
                )

                # é¢å¤–ç­‰å¾…åŠ¨æ€å†…å®¹åŠ è½½
                time.sleep(3)

                # æ¨¡æ‹Ÿäººç±»æµè§ˆè¡Œä¸º
                self.simulate_human_behavior()

                # ğŸ” æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œè°ƒè¯•æ—¶å¼€å¯ï¼‰
                # self.debug_page_status()

                # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ¯”èµ›æ•°æ®
                has_matches = self.has_match_data()
                if has_matches:
                    print("ğŸ† å‘ç°æ¯”èµ›æ•°æ®ï¼Œé¡µé¢æ­£å¸¸")
                    self.save_session()
                    return self.driver.page_source

                # å¦‚æœæ²¡æœ‰æ¯”èµ›æ•°æ®ï¼Œå†æ£€æŸ¥æ˜¯å¦ä¸ºæ­£å¸¸é¡µé¢
                if not self.is_normal_page():
                    print("âŒ é¡µé¢å¼‚å¸¸ï¼Œå°†é‡è¯•")
                    continue

                # åªæœ‰åœ¨é¡µé¢æ­£å¸¸ä½†æ— æ¯”èµ›æ•°æ®æ—¶ï¼Œæ‰æ£€æŸ¥æ˜¯å¦é‡åˆ°éªŒè¯ç 
                if self.check_anti_crawler():
                    print("ğŸš¨ æ£€æµ‹åˆ°éªŒè¯ç é¡µé¢")
                    # æ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯
                    self.debug_page_status()

                    action = self.handle_verification_enhanced()

                    if action == 'quit':
                        raise KeyboardInterrupt("ç”¨æˆ·é€‰æ‹©é€€å‡º")
                    elif action == 'skip':
                        return None
                    elif action == 'continue':
                        time.sleep(3)
                        # éªŒè¯åé‡æ–°æ£€æŸ¥
                        if self.has_match_data():
                            print("âœ… éªŒè¯åå‘ç°æ¯”èµ›æ•°æ®")
                            self.save_session()
                            return self.driver.page_source
                        elif self.is_normal_page() and not self.check_anti_crawler():
                            print("âœ… éªŒè¯åé¡µé¢æ­£å¸¸ï¼Œä½†å½“å¤©æ— æ¯”èµ›")
                            self.save_session()
                            return self.driver.page_source
                        else:
                            print("âŒ éªŒè¯åé—®é¢˜ä»å­˜åœ¨ï¼Œå°†é‡è¯•")
                            continue
                else:
                    # é¡µé¢æ­£å¸¸ä½†æ— æ¯”èµ›æ•°æ®ï¼ˆå¯èƒ½å½“å¤©å°±æ˜¯æ²¡æœ‰æ¯”èµ›ï¼‰
                    print("ğŸ“… é¡µé¢æ­£å¸¸ï¼Œå½“å¤©æ— æ¯”èµ›å®‰æ’")
                    self.save_session()
                    return self.driver.page_source

            except KeyboardInterrupt:
                raise
            except Exception as e:
                print(f"âŒ è®¿é—®å¤±è´¥ (å°è¯• {attempt + 1}): {e}")

        print(f"âŒ æ‰€æœ‰å°è¯•å‡å¤±è´¥: {url}")
        return None

    def parse_match_data(self, html_content):
        """è§£ææ¯”èµ›æ•°æ®ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        soup = BeautifulSoup(html_content, 'html.parser')
        matches = []

        match_rows = soup.find_all('tr', class_='each_match')
        print(f"ğŸˆ æ‰¾åˆ° {len(match_rows)} ä¸ªæ¯”èµ›è¡Œ")

        for tr in match_rows:
            try:
                match_data = {}

                # æå–åºå·
                match_id = tr.get('id')
                if match_id and match_id.startswith('match_detail_'):
                    match_id_num = match_id.replace('match_detail_', '')
                    match_data['åºå·'] = match_id_num

                    if match_id_num in self.existing_ids:
                        continue

                # æå–èµ›äº‹
                league_link = tr.find('a', class_='ssname')
                if league_link:
                    match_data['èµ›äº‹'] = league_link.get_text(strip=True)

                # æå–æ—¶é—´
                time_cells = tr.find_all('td', class_='graytx')
                for cell in time_cells:
                    cell_text = cell.get_text(strip=True)
                    if ':' in cell_text and ('-' in cell_text or '/' in cell_text):
                        match_data['æ—¶é—´'] = cell_text
                        break

                # æå–ä¸»é˜Ÿ
                home_link = tr.find('a', class_='ctrl_homename')
                if home_link:
                    home_name = home_link.get_text(strip=True)
                    home_td = home_link.find_parent('td')
                    if home_td:
                        rq_span = home_td.find('span', class_='rqObj')
                        if not rq_span:
                            rq_span = home_td.find('span', class_='ctrl_rq')

                        if rq_span:
                            rq_text = rq_span.get_text(strip=True)
                            if rq_text:
                                match_data['ä¸»é˜Ÿ'] = f"{home_name}{rq_text}"
                            else:
                                match_data['ä¸»é˜Ÿ'] = home_name
                        else:
                            match_data['ä¸»é˜Ÿ'] = home_name

                # æå–å®¢é˜Ÿ
                away_link = tr.find('a', class_='ctrl_awayname')
                if away_link:
                    match_data['å®¢é˜Ÿ'] = away_link.get_text(strip=True)

                # æå–æ¯”åˆ†
                home_score = tr.find('b', class_='ctrl_homescore')
                away_score = tr.find('b', class_='ctrl_awayscore')

                if home_score and away_score:
                    home_score_text = home_score.get_text(strip=True)
                    away_score_text = away_score.get_text(strip=True)
                    match_data['æ¯”åˆ†'] = f"{home_score_text}-{away_score_text}"

                # æå–èµ”ç‡
                odds_cell = tr.find('td', class_='blockbox')
                if not odds_cell:
                    odds_cell = tr.find('td', class_='ctrl_self_betopt')

                if odds_cell:
                    odds_spans = odds_cell.find_all('span')
                    odds_values = []

                    for span in odds_spans:
                        span_text = span.get_text(strip=True)
                        try:
                            if span_text and '.' in span_text:
                                odds_value = float(span_text)
                                if 1.0 < odds_value < 50.0:
                                    odds_values.append(span_text)
                        except ValueError:
                            continue

                    if len(odds_values) >= 1:
                        match_data['èƒœèµ”'] = odds_values[0]
                    if len(odds_values) >= 2:
                        match_data['å¹³èµ”'] = odds_values[1]
                    if len(odds_values) >= 3:
                        match_data['è´Ÿèµ”'] = odds_values[2]

                # éªŒè¯æ•°æ®å¹¶æ·»åŠ 
                if (match_data.get('ä¸»é˜Ÿ') and match_data.get('å®¢é˜Ÿ') and
                        match_data.get('åºå·') and match_data.get('åºå·') not in self.existing_ids):
                    matches.append(match_data)
                    self.existing_ids.add(match_data['åºå·'])
                    print(f"ğŸ“ æ–°å¢: {match_data.get('åºå·')} - {match_data.get('ä¸»é˜Ÿ')} vs {match_data.get('å®¢é˜Ÿ')}")

            except Exception as e:
                print(f"âŒ è§£æè¡Œæ•°æ®æ—¶å‡ºé”™: {e}")
                continue

        return matches

    def append_to_csv(self, matches):
        """è¿½åŠ æ•°æ®åˆ°CSVæ–‡ä»¶ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        if not matches:
            return

        fieldnames = ['åºå·', 'èµ›äº‹', 'æ—¶é—´', 'ä¸»é˜Ÿ', 'å®¢é˜Ÿ', 'æ¯”åˆ†', 'èƒœèµ”', 'å¹³èµ”', 'è´Ÿèµ”']
        file_exists = os.path.exists(self.csv_file)

        with open(self.csv_file, 'a', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            if not file_exists:
                writer.writeheader()

            for match in matches:
                row = {}
                for field in fieldnames:
                    row[field] = match.get(field, '')
                writer.writerow(row)

            print(f"ğŸ’¾ æˆåŠŸä¿å­˜ {len(matches)} åœºæ¯”èµ›åˆ° {self.csv_file}")

    def generate_date_range(self, start_date, end_date):
        """ç”Ÿæˆæ—¥æœŸèŒƒå›´ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        try:
            start_num = int(start_date)
            end_num = int(end_date)

            start_year_code = int(str(start_date)[:2])
            end_year_code = int(str(end_date)[:2])

            if start_year_code != end_year_code:
                print("âš ï¸ æš‚ä¸æ”¯æŒè·¨å¹´ä»½çˆ¬å–")
                return []

            dates = []
            current_num = start_num

            while current_num <= end_num:
                dates.append(str(current_num))
                current_num += 1

            return dates

        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ—¥æœŸèŒƒå›´æ—¶å‡ºé”™: {e}")
            return []

    def crawl_date_range(self, start_date, end_date, base_url="https://www.okooo.com/livecenter/danchang/?date="):
        """çˆ¬å–æ—¥æœŸèŒƒå›´æ•°æ®"""
        print(f"ğŸš€ å¼€å§‹çˆ¬å–æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")

        # å°è¯•åŠ è½½å·²ä¿å­˜çš„ä¼šè¯
        if self.load_session():
            print("âœ… ä½¿ç”¨å·²ä¿å­˜çš„ä¼šè¯ä¿¡æ¯")

        dates = self.generate_date_range(start_date, end_date)
        if not dates:
            return

        print(f"ğŸ“… æ€»å…±éœ€è¦çˆ¬å– {len(dates)} å¤©çš„æ•°æ®")

        total_new_matches = 0
        skipped_dates = []
        failed_dates = []

        for i, date in enumerate(dates, 1):
            try:
                url = f"{base_url}{date}"
                print(f"\n{'ğŸ†' * 30}")
                print(f"ğŸ“Š è¿›åº¦: {i}/{len(dates)} - æ—¥æœŸå‚æ•°: {date}")

                html_content = self.get_page_enhanced(url)

                if html_content is None:
                    skipped_dates.append(date)
                    continue

                matches = self.parse_match_data(html_content)

                if matches:
                    self.append_to_csv(matches)
                    total_new_matches += len(matches)
                    print(f"âœ… æ—¥æœŸ {date}: æ–°å¢ {len(matches)} åœºæ¯”èµ›")
                else:
                    print(f"âš ï¸ æ—¥æœŸ {date}: æ— æ–°å¢æ¯”èµ›æ•°æ®")

                # æ™ºèƒ½å»¶è¿Ÿ
                if i < len(dates):
                    delay = random.uniform(3, 8)
                    print(f"â±ï¸ ç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)

            except KeyboardInterrupt:
                print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œå·²çˆ¬å–åˆ°æ—¥æœŸ: {date}")
                break
            except Exception as e:
                print(f"âŒ çˆ¬å–æ—¥æœŸ {date} æ—¶å‡ºé”™: {e}")
                failed_dates.append(date)
                continue

        # æ˜¾ç¤ºæ€»ç»“
        print(f"\n{'ğŸ‰' * 30}")
        print("ğŸ“Š çˆ¬å–å®Œæˆç»Ÿè®¡:")
        print(f"âœ… æ€»å…±æ–°å¢: {total_new_matches} åœºæ¯”èµ›")
        print(f"âœ… æˆåŠŸçˆ¬å–: {len(dates) - len(skipped_dates) - len(failed_dates)} å¤©")
        if skipped_dates:
            print(f"âš ï¸ è·³è¿‡æ—¥æœŸ: {len(skipped_dates)} å¤©")
        if failed_dates:
            print(f"âŒ å¤±è´¥æ—¥æœŸ: {len(failed_dates)} å¤©")
        print(f"ğŸ“ æ•°æ®ä¿å­˜è‡³: {self.csv_file}")

    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            self.driver.quit()
            print("ğŸ”’ æµè§ˆå™¨å·²å…³é—­")


def main():
    print("ğŸ¤– æ¾³å®¢ç½‘å¢å¼ºç‰ˆåçˆ¬è™«çˆ¬è™«å¯åŠ¨")
    print("ğŸ“ å®‰è£…ä¾èµ–: pip install undetected-chromedriver")
    print("ğŸ›¡ï¸ æ”¯æŒè‡ªåŠ¨æ»‘å—éªŒè¯å’Œä¼šè¯ä¿æŒ")
    print("-" * 50)

    spider = None
    try:
        spider = EnhancedOkoooSpider(headless=False)

        start_date = "25011"
        end_date = "25081"

        spider.crawl_date_range(start_date, end_date)

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸»åŠ¨åœæ­¢")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if spider:
            spider.close()


if __name__ == "__main__":
    main()